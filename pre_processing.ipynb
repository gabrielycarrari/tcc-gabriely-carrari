{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielycarrari/tcc/blob/pre-processing/pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook para Pré-processamento"
      ],
      "metadata": {
        "id": "6VIUkzuXJCki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importações"
      ],
      "metadata": {
        "id": "sdnfrXU5JIBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qre6v-btJXZs",
        "outputId": "a3348957-e890-4e80-c09e-2d3e073b1e57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "n3TSHVRGNtjb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "olebgUsl08B0"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=userdata.get('HUGGINGFACE_TOKEN'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm-9CjUoJcgK",
        "outputId": "5acd00a2-4075-4942-c8ef-9499332342ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset Common Voice 17\n",
        "dataset = load_dataset(\"mozilla-foundation/common_voice_17_0\", \"pt\", split='train', trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OnD5x-t_Jr6Z",
        "outputId": "91f2632c-b6a7-4722-b037-8aafa23c1d88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testes"
      ],
      "metadata": {
        "id": "QoaKNasZTkXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "-OzMVEZIM6tO",
        "outputId": "2a1a0414-697d-4006-af99-a76d187514e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'client_id': 'df268ebd4060c8106179019a8bb331f8db173023c64d4e56a38a54f77f2fe6706480320965871d1b8d11da18601c241c8c4b80dc44d3ff9a32ee54991f5c0e99',\n",
              " 'path': '/root/.cache/huggingface/datasets/downloads/extracted/fe3a346df3c979ff3eb48fa107c50894678ab25af4c6f7785dec890ecdff72f7/pt_train_0/common_voice_pt_33954672.mp3',\n",
              " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/fe3a346df3c979ff3eb48fa107c50894678ab25af4c6f7785dec890ecdff72f7/pt_train_0/common_voice_pt_33954672.mp3',\n",
              "  'array': array([ 1.77635684e-15, -5.41788836e-14, -9.05941988e-14, ...,\n",
              "          1.72863140e-10,  1.45055787e-10,  7.10012743e-11]),\n",
              "  'sampling_rate': 48000},\n",
              " 'sentence': 'Sinta-se feliz com a vitória que você ganha.',\n",
              " 'up_votes': 4,\n",
              " 'down_votes': 0,\n",
              " 'age': 'thirties',\n",
              " 'gender': 'male_masculine',\n",
              " 'accent': 'Minas Gerais',\n",
              " 'locale': 'pt',\n",
              " 'segment': '',\n",
              " 'variant': 'Portuguese (Brasil)'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]['sentence']"
      ],
      "metadata": {
        "id": "IFvdkxqOM0UV",
        "outputId": "232b23f7-c6da-4d75-a493-d60b998fb6ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Sinta-se feliz com a vitória que você ganha.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = tf.io.read_file('/content/samples_pt_sample.wav')"
      ],
      "metadata": {
        "id": "r6UF6sP3QHmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import tensorflow as tf\n",
        "import soundfile as sf\n",
        "\n",
        "# Load the audio file with librosa\n",
        "audio_data, sample_rate = librosa.load('/content/samples_pt_sample.wav', sr=None)\n",
        "\n",
        "# Resample to 16kHz (if necessary)\n",
        "target_sample_rate = 16000\n",
        "if sample_rate != target_sample_rate:\n",
        "    audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
        "\n",
        "# Save the resampled audio as a WAV file\n",
        "sf.write('resampled_audio.wav', audio_data, target_sample_rate)\n",
        "\n",
        "# Load the resampled file using tensorflow\n",
        "file = tf.io.read_file('resampled_audio.wav')\n",
        "audio, _ = tf.audio.decode_wav(file)"
      ],
      "metadata": {
        "id": "jDppOpaUQRMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = tf.squeeze(audio, axis=-1)\n",
        "# 3. Change type to float\n",
        "audio = tf.cast(audio, tf.float32)"
      ],
      "metadata": {
        "id": "o6clLmbLSCZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio"
      ],
      "metadata": {
        "id": "MjK18BfgSJMt",
        "outputId": "32e43284-4c52-4c02-f259-e35f125b855b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(74240,), dtype=float32, numpy=\n",
              "array([2.2583008e-03, 2.4719238e-03, 1.5869141e-03, ..., 3.0517578e-05,\n",
              "       9.1552734e-05, 9.1552734e-05], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio2 = dataset[0]['audio']['array']\n",
        "sampling_rate = dataset[0]['audio']['sampling_rate']\n",
        "\n",
        "# 2. Convert audio to a tensor\n",
        "audio2 = tf.convert_to_tensor(audio2, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "pvVgiXWGSSnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]['audio']['sampling_rate']"
      ],
      "metadata": {
        "id": "k2-qpLqpTNnR",
        "outputId": "cb334e4a-a9d9-4575-9c38-53c0741ce46e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48000"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio2"
      ],
      "metadata": {
        "id": "0BInuQkjStyV",
        "outputId": "dc754bee-9144-4b61-dedc-fcab4e2f9f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(195264,), dtype=float32, numpy=\n",
              "array([ 1.7763568e-15, -5.4178884e-14, -9.0594199e-14, ...,\n",
              "        1.7286314e-10,  1.4505579e-10,  7.1001274e-11], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definindo Caracteres"
      ],
      "metadata": {
        "id": "DdNOyJjBKyy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The set of characters accepted in the transcription.\n",
        "characters = [x for x in \"abcdefghijklmnopqrstuvwxyzáàâãéêíóôõúç'?!.- \"]\n",
        "\n",
        "# Mapping characters to integers\n",
        "char_to_num = keras.layers.StringLookup(vocabulary=characters, oov_token=\"\")\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char = keras.layers.StringLookup(\n",
        "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
        "    f\"(size={char_to_num.vocabulary_size()})\"\n",
        ")"
      ],
      "metadata": {
        "id": "r_VSvCsMKzXx",
        "outputId": "78bdb8e9-1e02-4931-b23a-0c9aa73b123b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'á', 'à', 'â', 'ã', 'é', 'ê', 'í', 'ó', 'ô', 'õ', 'ú', 'ç', \"'\", '?', '!', '.', '-', ' '] (size=45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "hBwR9hcROUSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The window length in samples.\n",
        "frame_length = 256\n",
        "# The number of samples to step.\n",
        "frame_step = 160\n",
        "# The size of the FFT to apply.\n",
        "fft_length = 384"
      ],
      "metadata": {
        "id": "ZRppM8pQOT7s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_single_sample(audio, label):\n",
        "  ###########################################\n",
        "  ##  Process the Audio\n",
        "  ##########################################\n",
        "  # 1. Read wav file\n",
        "  # file = tf.io.read_file(wavs_path + wav_file + \".wav\")\n",
        "  # 2. Decode the wav file\n",
        "  # audio, _ = tf.audio.decode_wav(file)\n",
        "  # audio = tf.squeeze(audio, axis=-1)\n",
        "  # 3. Change type to float\n",
        "  # audio = tf.cast(audio, tf.float32)\n",
        "\n",
        "  # 2. Convert audio to a tensor\n",
        "  audio = tf.convert_to_tensor(audio, dtype=tf.float32)\n",
        "\n",
        "  # 4. Get the spectrogram\n",
        "  spectrogram = tf.signal.stft(\n",
        "      audio, frame_length=frame_length, frame_step=frame_step, fft_length=fft_length\n",
        "  )\n",
        "  # 5. We only need the magnitude, which can be derived by applying tf.abs\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  spectrogram = tf.math.pow(spectrogram, 0.5)\n",
        "  # 6. normalisation\n",
        "  means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)\n",
        "  stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)\n",
        "  spectrogram = (spectrogram - means) / (stddevs + 1e-10)\n",
        "\n",
        "\n",
        "  ###########################################\n",
        "  ##  Process the label\n",
        "  ##########################################\n",
        "  # 7. Convert label to Lower case\n",
        "  label = tf.strings.lower(label)\n",
        "  # 8. Split the label\n",
        "  label = tf.strings.unicode_split(label, input_encoding=\"UTF-8\")\n",
        "  # 9. Map the characters in label to numbers\n",
        "  label = char_to_num(label)\n",
        "  # 10. Return a dict as our model is expecting two inputs\n",
        "  return spectrogram, label"
      ],
      "metadata": {
        "id": "Nvm95dLjTt14"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio = dataset[0]['audio']['array']"
      ],
      "metadata": {
        "id": "OHvmGPxFJCcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrogram, label = encode_single_sample(dataset[0]['audio']['array'], dataset[0]['sentence'])"
      ],
      "metadata": {
        "id": "3Wk36MHKJa_k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectrogram"
      ],
      "metadata": {
        "id": "zT0_tBboMNh_",
        "outputId": "3e48a87e-45ba-44ee-d05c-d210923f5c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1219, 193), dtype=float32, numpy=\n",
              "array([[ 1.6657089 ,  1.7006105 ,  1.8479182 , ..., -0.82513076,\n",
              "        -0.83893055, -0.829094  ],\n",
              "       [ 1.999373  ,  1.7483722 ,  1.4855099 , ..., -0.81034017,\n",
              "        -0.80858064, -0.8089801 ],\n",
              "       [ 0.7909164 ,  0.95239437,  1.2188578 , ..., -0.80961126,\n",
              "        -0.8095434 , -0.80952334],\n",
              "       ...,\n",
              "       [ 0.2551299 ,  0.8557077 ,  0.9137746 , ..., -0.86999285,\n",
              "        -0.87001526, -0.8697995 ],\n",
              "       [ 0.6691177 ,  0.6066629 ,  0.76785856, ..., -0.87769675,\n",
              "        -0.8774716 , -0.8778401 ],\n",
              "       [ 0.65872556,  0.49569604,  0.69298553, ..., -0.87480515,\n",
              "        -0.88802457, -0.87769204]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "id": "R8dxRG_hLq9T",
        "outputId": "7acfb424-de40-4500-e06b-d134bd4c6f24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(44,), dtype=int64, numpy=\n",
              "array([19,  9, 14, 20,  1, 43, 19,  5, 44,  6,  5, 12,  9, 26, 44,  3, 15,\n",
              "       13, 44,  1, 44, 22,  9, 20, 34, 18,  9,  1, 44, 17, 21,  5, 44, 22,\n",
              "       15,  3, 32, 44,  7,  1, 14,  8,  1, 42])>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em conjuntos de treinamento e validação\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "IbNd54MvOQBD",
        "outputId": "fd10d29d-b111-45ef-cbf4-72c94aa766ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-20037fb5777f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dividir os dados em conjuntos de treinamento e validação\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(dataset['audio']['array'], dataset['sentence'], test_size=0.10, random_state=42)"
      ],
      "metadata": {
        "id": "79yjDLVnQis7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets. 90/10.\n",
        "split = int(len(dataset) * 0.90)\n",
        "# df_train = metadata_df[:split]\n",
        "df_val = dataset[split:]\n",
        "\n",
        "# print(f\"Size of the training set: {len(df_train)}\")\n",
        "print(f\"Size of the training set: {len(df_val)}\")"
      ],
      "metadata": {
        "id": "eBA2oqQpN2zM",
        "outputId": "531100ad-d754-4908-b0a7-b61383b462ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the training set: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "i-T02sJvPK5y",
        "outputId": "7243b437-e2dd-413e-ce16-f6a71f4ea86e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21968"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ig6fu9WOp1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (list(dataset['audio']['array']), list(dataset['sentence']))\n",
        ")"
      ],
      "metadata": {
        "id": "9QNbA056Nodi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}